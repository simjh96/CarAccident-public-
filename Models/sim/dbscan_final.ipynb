{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SBUjsZkcrtTg"
   },
   "outputs": [],
   "source": [
    "# !pip install pyproj\n",
    "# !pip install geopandas\n",
    "# !pip install vincent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uL0gnOcErzu6"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from functools import partial\n",
    "from shapely import ops\n",
    "import pyproj\n",
    "import json, math\n",
    "import matplotlib.pyplot as plt\n",
    "from folium import plugins\n",
    "import re\n",
    "from matplotlib import font_manager, rc, rcParams\n",
    "from shapely.geometry import Point as shapely_Point\n",
    "from geopy.distance import great_circle as distance\n",
    "from geopy.point import Point as Point\n",
    "from math import sin, cos, atan2, sqrt, degrees, radians, pi\n",
    "from IPython.display import display\n",
    "import branca\n",
    "from branca.colormap import linear\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "from folium import plugins\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import os\n",
    "import datetime\n",
    "def reproject(geom, from_proj=None, to_proj=None):\n",
    "    tfm = partial(pyproj.transform, pyproj.Proj(init=from_proj), pyproj.Proj(init=to_proj))\n",
    "    return ops.transform(tfm, geom)\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import silhouette_score\n",
    "from itertools import combinations\n",
    "center = (37.1623799231016, 127.05436890115905)\n",
    "plt.style.use(['ggplot'])\n",
    "rs = 123\n",
    "np.random.seed(rs)\n",
    "random.seed(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "BRbpdTDArz3p",
    "outputId": "a5800279-d6fc-4b7d-cacc-12a120658d9e"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('C:/Users/simjh96/OneDrive/문서/Car_Accident/model/data/feature25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xR7Idoxwrz7B"
   },
   "outputs": [],
   "source": [
    "learn_cols = [\"lon\",\n",
    "              \"lat\",\n",
    "              \"overspeed_cam_count100\",\n",
    "              \"floating_pop_count50\",\n",
    "              \"shortest_bump_dist\",\n",
    "              \"parking_count12.5\",\n",
    "              \"parking_count25\",\n",
    "              \"car_count1000\", \n",
    "              \"child_count1000\",\n",
    "              \"elem_kinder_count400\",\n",
    "              \"numberSchoolZone_count400\",\n",
    "              \"num_cram_school_count400\",\n",
    "              \"shortest_cross_dist\",\n",
    "              \"shortest_traffic_signal_dist\",\n",
    "              \"shortest_sidewalk_dist\",\n",
    "              \"barrier_nearby_count12.5\",\n",
    "              \"barrier_nearby_count25\",\n",
    "              \"chaos1_nearby_count12.5\",\n",
    "              \"chaos1_nearby_count25\",\n",
    "              \"width_nearby_count12.5\",\n",
    "              \"width_nearby_count25\",\n",
    "              \"cross_road_nearby_count12.5\",\n",
    "              \"cross_road_nearby_count25\"]\n",
    "\n",
    "clust_cols = [\"floating_pop_count50\",\n",
    "        \"parking_count25\",\n",
    "        \"car_count1000\", \n",
    "        \"child_count1000\",\n",
    "        \"elem_kinder_count400\",\n",
    "        \"numberSchoolZone_count400\",\n",
    "        \"chaos1_nearby_count25\",\n",
    "        \"cross_road_nearby_count25\",\n",
    "        \"num_cram_school_count400\",\n",
    "        \"shortest_cross_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bEZfh2S_rz-h"
   },
   "outputs": [],
   "source": [
    "#df1 feature 조절\n",
    "#groupby로 count 하고\n",
    "#등간이라고 생각되는 만큼 조절\n",
    "df1.elem_kinder_count400.loc[df1.elem_kinder_count400 == 0] = 0\n",
    "df1.elem_kinder_count400.loc[(df1.elem_kinder_count400 > 0)&(df1.elem_kinder_count400 <= 10)] = 1\n",
    "df1.elem_kinder_count400.loc[(df1.elem_kinder_count400 > 10)] = 2\n",
    "\n",
    "df1.numberSchoolZone_count400.loc[(df1.numberSchoolZone_count400 ==0 )] = 0\n",
    "df1.numberSchoolZone_count400.loc[(df1.numberSchoolZone_count400 > 0)&(df1.numberSchoolZone_count400 <= 2)] = 1\n",
    "df1.numberSchoolZone_count400.loc[(df1.numberSchoolZone_count400 > 2)] = 2\n",
    "\n",
    "df1.num_cram_school_count400.loc[(df1.num_cram_school_count400 ==0 )] = 0\n",
    "df1.num_cram_school_count400.loc[(df1.num_cram_school_count400 > 0)&(df1.num_cram_school_count400 <= 31)] = 1\n",
    "df1.num_cram_school_count400.loc[(df1.num_cram_school_count400 > 31)] = 2\n",
    "\n",
    "df1[\"accident_count12.5\"] = (df1[\"accident_count12.5\"] > 0).astype(float)\n",
    "\n",
    "df1['is_bump20'] = df1['shortest_bump_dist'] < 20\n",
    "df1['is_sidewalk12.5'] = df1['shortest_sidewalk_dist'] < 12.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6rSkgEP-r0BK"
   },
   "outputs": [],
   "source": [
    "df1.loc[:,:] = MinMaxScaler().fit_transform(df1)\n",
    "\n",
    "x25 = df1.loc[:,learn_cols]\n",
    "y25 = df1[\"accident_count12.5\"]\n",
    "\n",
    "x25_train, x25_test, y25_train, y25_test = train_test_split(x25, y25, test_size=0.33, random_state=3)\n",
    "\n",
    "df2 = df1.loc[:,clust_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8y0HEQuWnTKP"
   },
   "outputs": [],
   "source": [
    "#cluster 중앙값 구하는 \n",
    "def centre(cluster_id):\n",
    "  currentMinimum = 99999\n",
    "  datas = df2.loc[labels_s == cluster_id,:].to_numpy()\n",
    "  \n",
    "  for point_idx in range(len(datas)):\n",
    "      distance_sum = 0\n",
    "      for second_point_idx in range(len(datas)):\n",
    "          if point_idx == second_point_idx : continue\n",
    "          distance_sum += np.linalg.norm(datas[point_idx] - datas[second_point_idx])\n",
    "      # print('>>>>>', point_idx, distance_sum) \n",
    "\n",
    "      if distance_sum < currentMinimum :\n",
    "          currentMinimum = distance_sum \n",
    "          centre_point = datas[point_idx]\n",
    "  return centre_point\n",
    "\n",
    "#클러스터 끼리 중앙값중 가장 짧은 클러스터 구하기\n",
    "def closest(cluster_id, ban_list):\n",
    "  currentMinimum = 99999\n",
    "  clusters = list(set(labels_s))\n",
    "  centre_point = centre(cluster_id)\n",
    "\n",
    "  distance = 0\n",
    "  for second_point_idx in range(len(clusters)):\n",
    "    if cluster_id == clusters[second_point_idx] or (clusters[second_point_idx] in ban_list): continue\n",
    "    distance = np.linalg.norm(centre_point - centre(clusters[second_point_idx]))\n",
    "    # print('>>>>>', second_point_idx, distance) \n",
    "\n",
    "    if distance < currentMinimum :\n",
    "      currentMinimum = distance \n",
    "      closest_clust = clusters[second_point_idx]\n",
    "\n",
    "  return closest_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "L8UQXk4tl6hN",
    "outputId": "95597f2d-2012-444f-d6fa-20a3504fbb27"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-78f8fb98bd13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmin_s\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0mneighbors_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;31m# This has worst case O(n^2) memory complexity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         neighborhoods = neighbors_model.radius_neighbors(X,\n\u001b[0m\u001b[0;32m    337\u001b[0m                                                          return_distance=False)\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m    966\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"prefer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"threads\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[0;32m    969\u001b[0m                 delayed_query(self._tree, X[s], radius, return_distance,\n\u001b[0;32m    970\u001b[0m                               sort_results=sort_results)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\trial2\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_radius_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[0mcloudpickle\u001b[0m \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \"\"\"\n\u001b[1;32m--> 790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_radius\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hyper param search\n",
    "indexs = []\n",
    "for min_s in range(2,20,4):\n",
    "  for eps in np.linspace(0.01,1,20):\n",
    "    indexs.append([eps, min_s])\n",
    "\n",
    "animate = []\n",
    "scores = []\n",
    "n_clusters = []\n",
    "n_noise = []\n",
    "for min_s in range(2,20,4):\n",
    "  for eps in np.linspace(0.01,1,20):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_s).fit(df2)\n",
    "    labels = db.labels_\n",
    "\n",
    "    df3 = pd.concat([df2,pd.DataFrame(db.labels_)],axis=1)\n",
    "    animate.append(df3.groupby(0).count().floating_pop_count50)\n",
    "    try:\n",
    "      scores.append(metrics.silhouette_score(df2, db.labels_))\n",
    "    except:\n",
    "      scores.append(-1)\n",
    "    n_clusters.append(len(set(labels)) - (1 if -1 in labels else 0))\n",
    "    n_noise.append(list(labels).count(-1))\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "def animate_f(i):\n",
    "    x = animate[i].index\n",
    "    y = animate[i]\n",
    "    line.set_data(x, y)\n",
    "    ax.set_title('eps, min_samples = {}\\n Silhouette Coefficient: {}'.format(indexs[i],scores[i]))\n",
    "    return (line,)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlim(( -2, 300))\n",
    "ax.set_ylim((0, 5000))\n",
    "\n",
    "line, = ax.plot([], [], lw=2)\n",
    "\n",
    "# anim = animation.FuncAnimation(fig, animate_f, init_func=init,\n",
    "#                                frames=len(indexs), interval=len(indexs), blit=True)\n",
    "\n",
    "# HTML(anim.to_html5_video())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "XpDBw2BSffAB",
    "outputId": "61b0a336-d94f-4d36-ff2b-66adfe3f901e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "X_Gm7k7He93e",
    "outputId": "2f4f85f5-4f02-4bd9-8157-86b2384758f1"
   },
   "outputs": [],
   "source": [
    "#동질성이 보장될 클러스터 갯수 중 실루엣 가장 큰값\n",
    "p = pd.concat([pd.DataFrame(scores),pd.DataFrame(n_clusters),pd.DataFrame(n_noise),pd.DataFrame(indexs)],axis=1)\n",
    "p.columns = ['scores','n_clusters','n_noise','eps','min_sample']\n",
    "p.sort_values(['scores']).iloc[-60:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlCQjTsSfFVZ",
    "outputId": "99b9b448-a2d4-470c-bf26-2f1c8c69a6e0"
   },
   "outputs": [],
   "source": [
    "#클러스터링 후 모든 클러스터 각각에 logistic 진행\n",
    "\n",
    "db = DBSCAN(eps=0.088421, min_samples=2).fit(df2)\n",
    "labels_s = db.labels_\n",
    "\n",
    "x25_train_l = pd.concat([df2,pd.DataFrame(labels_s)],axis=1).loc[x25_train.index,:].sort_index()\n",
    "x25_test_l = pd.concat([df2,pd.DataFrame(labels_s)],axis=1).loc[x25_test.index,:].sort_index()\n",
    "\n",
    "test_predict_set = []\n",
    "x25_test0_indexs = []\n",
    "\n",
    "ban_list = list(set(x25_test_l.loc[:,0]) - set(x25_train_l.loc[:,0]))\n",
    "\n",
    "for i in list(set(labels_s)):\n",
    "  # 2nd clust == 0 인거 해보자\n",
    "  if i in ban_list:\n",
    "    closest_clust = closest(i,ban_list)\n",
    "    print(i,\"->\",closest_clust)\n",
    "    i = closest_clust\n",
    "\n",
    "  x25_train0 = x25_train[x25_train_l.loc[:,0] == i]\n",
    "  y25_train0 = y25_train[x25_train_l.loc[:,0] == i]\n",
    "  x25_test0 = x25_test[x25_test_l.loc[:,0] == i]\n",
    "  y25_test0 = y25_test[x25_test_l.loc[:,0] == i]\n",
    "\n",
    "  if sum(x25_test_l.loc[:,0] == i) == 0: continue\n",
    "  x25_test0_indexs.append(x25_test_l.loc[x25_test_l.loc[:,0] == i].index)\n",
    "\n",
    "  model = sm.Logit(y25_train0,sm.add_constant(x25_train0,has_constant = \"add\"))  \n",
    "  results = model.fit(method= 'lbfgs',maxiter =1000)\n",
    "  predictions = results.predict(sm.add_constant(x25_test0,has_constant = \"add\"))\n",
    "  print(i,'번째 F1 score',f1_score(y25_test0.astype(int),(predictions > 0.5).astype(int)))\n",
    "  print(\" \")\n",
    "\n",
    "  test_predict_set.append([y25_test0,(predictions > 0.5).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "qGBDmJENoYMX",
    "outputId": "96e459e4-a7bb-44bf-ef89-56828306a8eb"
   },
   "outputs": [],
   "source": [
    "#전체 y25_test(2224개)에 대한 prediction 값 concat\n",
    "y = pd.DataFrame(test_predict_set[0][0])\n",
    "pr = pd.DataFrame(test_predict_set[0][1])\n",
    "for i in range(len(test_predict_set)):\n",
    "  if i == 0:continue\n",
    "  y = pd.concat((y,pd.DataFrame(test_predict_set[i][0])))\n",
    "  pr = pd.concat((pr,pd.DataFrame(test_predict_set[i][1])))\n",
    "\n",
    "\n",
    "print(f1_score(y.to_numpy().reshape(len(y)),pr.to_numpy().reshape(len(pr))))\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2,figsize=(40,10), sharex=True,sharey=True)\n",
    "ax1.plot(y.to_numpy().reshape(len(y)))\n",
    "ax2.plot(pr.to_numpy().reshape(len(pr)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0123 1930의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:trial2] *",
   "language": "python",
   "name": "conda-env-trial2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
